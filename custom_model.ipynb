{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# essentials\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# tensorflow tools\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import imagenet_utils\n",
    "from keras import Model\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, Concatenate, Add, Activation, Dropout, GlobalAveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filepaths to training and test sets\n",
    "base_dir = './data/Fruits-360/fruits-360_dataset/fruits-360'\n",
    "\n",
    "train_filepaths = list(Path(base_dir + '/Training').glob(r'**/*.jpg'))\n",
    "test_filepaths = list(Path(base_dir + '/Test').glob(r'**/*.jpg'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtaining labels from filepaths function\n",
    "def get_fruit_label(filepaths):\n",
    "    labels = [str(filepath).split('\\\\')[-2].split(' ')[0] for filepath in filepaths]\n",
    "\n",
    "    filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    fruits_df = pd.concat([filepaths, labels], axis=1)\n",
    "\n",
    "    return fruits_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating datasets with image filepaths and corresponding labels\n",
    "train_df = get_fruit_label(train_filepaths)\n",
    "test_df = get_fruit_label(test_filepaths)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Getting a list of labels\n",
    "label_list = train_df.Label.unique().tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fixed parameters\n",
    "image_size = (224, 224, 3)\n",
    "batch_size = 32\n",
    "num_classes = len(label_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating data generators for training and test sets\n",
    "train_datagen = image.ImageDataGenerator(\n",
    "    validation_split=0.2,\n",
    "    rotation_range=180,\n",
    "    shear_range=10,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = image.ImageDataGenerator()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_gen = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    target_size=image_size[:-1]\n",
    ")\n",
    "\n",
    "validation_gen = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True,\n",
    "    target_size=image_size[:-1]\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    target_size=image_size[:-1]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Custom model </h1>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Custom preprocess function\n",
    "def custom_preprocess(input_image):\n",
    "    return imagenet_utils.preprocess_input(input_image, mode='tf')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Applying custom preprocess function on train and test data generators\n",
    "train_datagen.preprocessing_function = custom_preprocess\n",
    "test_datagen.preprocessing_function = custom_preprocess"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Custom Inception-Residual block\n",
    "def custom_block(input_layer, filters, name=None):\n",
    "    padding = 'same'\n",
    "    f1, f2, f3, f4 = filters\n",
    "\n",
    "    input_shortcut = input_layer\n",
    "\n",
    "    branch0 = Conv2D(filters=f1, kernel_size=(1, 1) , strides=(1, 1), padding=padding, activation='relu', name=name+'_b0')(input_layer)\n",
    "    branch1 = Conv2D(filters=f2, kernel_size=(1, 1), strides=(1, 1), padding=padding, activation='relu', name=name+'_b1_0')(input_layer)\n",
    "    branch1 = Conv2D(filters=f3, kernel_size=(3, 3), strides=(1, 1), padding=padding, activation='relu', name=name+'_b1_1')(branch1)\n",
    "\n",
    "    mixed = Concatenate(axis=3, name=name+'_concat')([branch0, branch1])\n",
    "    filexp = Conv2D(filters=f4, kernel_size=(1, 1), strides=(1, 1), padding=padding, name=name+'_filexp')(mixed)\n",
    "\n",
    "    output = Add()([input_shortcut, filexp])\n",
    "    output = Activation('relu')(output)\n",
    "\n",
    "    return output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Custom model architecture\n",
    "def custom_model(n_classes, input_shape=(224, 224, 3)):\n",
    "\n",
    "    x_input = Input(input_shape)\n",
    "\n",
    "    x = Conv2D(32, kernel_size=(3, 3), strides=(2, 2), padding='valid', activation='relu', name='conv1')(x_input)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu', name='conv2')(x)\n",
    "    x = Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu', name='conv3')(x)\n",
    "\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid', name='maxpool1')(x)\n",
    "\n",
    "    x = custom_block(x, [48, 32, 64, 128], 'block1')\n",
    "    x = Conv2D(256, kernel_size=(3, 3), strides=(2, 2), padding='valid', activation='relu', name='conv4')(x)\n",
    "    x = custom_block(x, [96, 64, 128, 256], 'block2')\n",
    "    x = Conv2D(512, kernel_size=(3, 3), strides=(2, 2), padding='valid', activation='relu', name='conv5')(x)\n",
    "\n",
    "    x = GlobalAveragePooling2D(data_format='channels_last')(x)\n",
    "    x = Dropout(0.2, name='dropout1')(x)\n",
    "    x = Dense(n_classes, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=x_input, outputs=x)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Custom model construction and compilation\n",
    "model_custom = custom_model(num_classes, image_size)\n",
    "model_custom.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting custom model's architecture\n",
    "plot_model(model_custom, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating callbacks\n",
    "log_dir = \"logs/Custom_model/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "checkpoint_callback = ModelCheckpoint('custom_model.h5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "earlystopping_callback = EarlyStopping(monitor='val_loss', mode='min', patience=3, restore_best_weights=True)\n",
    "\n",
    "callbacks = [tensorboard_callback, checkpoint_callback, earlystopping_callback]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Custom model learning\n",
    "history_custom = model_custom.fit(train_gen, validation_data=validation_gen, epochs=25, callbacks=callbacks)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loading of the best weights achieved\n",
    "model_custom.load_weights('custom_model.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Custom model evaluation\n",
    "loss_custom, accuracy_custom = model_custom.evaluate(test_gen)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting a sample of images with predicted and true labels\n",
    "test_datagen.preprocessing_function = None\n",
    "X_sample, y_sample = test_gen.next()\n",
    "\n",
    "apply_preprocess = np.vectorize(custom_preprocess)\n",
    "predictions_custom = model_custom.predict(apply_preprocess(X_sample), verbose=0)\n",
    "\n",
    "predictions_custom = [label_list[np.argmax(prediction)] for prediction in predictions_custom]\n",
    "true_labels_custom = [label_list[np.argmax(sample)] for sample in y_sample]\n",
    "\n",
    "fig, axes = plt.subplots(4, 8, figsize=(15, 7), subplot_kw={'xticks' : [], 'yticks' : []})\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_sample[i]/255.)\n",
    "    ax.set_title(f'True: {true_labels_custom[i]}\\nPredicted: {predictions_custom[i]}', fontsize=8)\n",
    "plt.tight_layout(pad=0.5)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}